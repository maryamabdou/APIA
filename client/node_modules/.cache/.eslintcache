[{"/home/maryam/grad_project/src/index.js":"1","/home/maryam/grad_project/src/App.js":"2","/home/maryam/grad_project/src/reportWebVitals.js":"3","/home/maryam/grad_project/src/Interview/WebGazer.jsx":"4","/home/maryam/grad_project/src/Interview/Interview.jsx":"5","/home/maryam/grad_project/src/Interview/SpeechReader.jsx":"6","/home/maryam/Documents/GitHub/graduation_project/client/src/index.js":"7","/home/maryam/Documents/GitHub/graduation_project/client/src/reportWebVitals.js":"8","/home/maryam/Documents/GitHub/graduation_project/client/src/App.js":"9","/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/Interview.jsx":"10","/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/SpeechToText.jsx":"11","/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/Avatar.jsx":"12","/home/maryam/Documents/GitHub/graduation_project/client/src/components/Navbar.jsx":"13","/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/WebGazer.jsx":"14","/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/SpeechReader.jsx":"15"},{"size":535,"mtime":1699530968017,"results":"16","hashOfConfig":"17"},{"size":164,"mtime":1701641497504,"results":"18","hashOfConfig":"17"},{"size":362,"mtime":1699530968017,"results":"19","hashOfConfig":"17"},{"size":1954,"mtime":1701642641938,"results":"20","hashOfConfig":"17"},{"size":260,"mtime":1701642056090,"results":"21","hashOfConfig":"17"},{"size":2244,"mtime":1701642568553,"results":"22","hashOfConfig":"17"},{"size":535,"mtime":1699530968017,"results":"23","hashOfConfig":"24"},{"size":362,"mtime":1701643886867,"results":"25","hashOfConfig":"24"},{"size":223,"mtime":1706644706406,"results":"26","hashOfConfig":"24"},{"size":884,"mtime":1706642048785,"results":"27","hashOfConfig":"24"},{"size":157,"mtime":1706621116490,"results":"28","hashOfConfig":"24"},{"size":399,"mtime":1706641893647,"results":"29","hashOfConfig":"24"},{"size":139,"mtime":1706619505304,"results":"30","hashOfConfig":"24"},{"size":1709,"mtime":1706638263309,"results":"31","hashOfConfig":"24"},{"size":2247,"mtime":1706618910980,"results":"32","hashOfConfig":"24"},{"filePath":"33","messages":"34","suppressedMessages":"35","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"9p0qe2",{"filePath":"36","messages":"37","suppressedMessages":"38","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"39","messages":"40","suppressedMessages":"41","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"42","messages":"43","suppressedMessages":"44","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"45","messages":"46","suppressedMessages":"47","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"48","messages":"49","suppressedMessages":"50","errorCount":1,"fatalErrorCount":0,"warningCount":6,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"51","messages":"52","suppressedMessages":"53","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"31hvf0",{"filePath":"54","messages":"55","suppressedMessages":"56","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"57","messages":"58","suppressedMessages":"59","errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"60","messages":"61","suppressedMessages":"62","errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"63"},{"filePath":"64","messages":"65","suppressedMessages":"66","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"67","messages":"68","suppressedMessages":"69","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"70"},{"filePath":"71","messages":"72","suppressedMessages":"73","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"74","messages":"75","suppressedMessages":"76","errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"77"},{"filePath":"78","messages":"79","suppressedMessages":"80","errorCount":0,"fatalErrorCount":0,"warningCount":6,"fixableErrorCount":0,"fixableWarningCount":0,"source":"81"},"/home/maryam/grad_project/src/index.js",[],[],"/home/maryam/grad_project/src/App.js",[],[],"/home/maryam/grad_project/src/reportWebVitals.js",[],[],"/home/maryam/grad_project/src/Interview/WebGazer.jsx",["82","83","84","85"],[],"/home/maryam/grad_project/src/Interview/Interview.jsx",["86"],[],"/home/maryam/grad_project/src/Interview/SpeechReader.jsx",["87","88","89","90","91","92","93"],[],"/home/maryam/Documents/GitHub/graduation_project/client/src/index.js",[],[],"/home/maryam/Documents/GitHub/graduation_project/client/src/reportWebVitals.js",[],[],"/home/maryam/Documents/GitHub/graduation_project/client/src/App.js",["94","95"],[],"/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/Interview.jsx",["96","97"],[],"import React, { useEffect } from \"react\";\nimport { Box, Stack } from \"@mui/material\";\nimport Navbar from \"../../components/Navbar.jsx\";\nimport WebGazer from './WebGazer';\nimport SpeechReader from \"./SpeechReader\";\nimport Avatar from \"./Avatar.jsx\";\nimport SpeechToText from \"./SpeechToText.jsx\"\n\nfunction Interview() {\n  \n  return(\n    <div>\n      {/* <WebGazer /> */}\n      <Stack direction=\"column\" spacing={2}>\n        <Box sx={{ backgroundColor: \"white\", height: \"7vh\"}}>\n          <Navbar />\n        </Box>\n\n        <Box sx={{ backgroundColor: \"white\", height: \"75vh\"}}>\n          <Avatar />\n        </Box>\n\n        <Box sx={{ backgroundColor: \"white\", height: \"7vh\"}}>\n          <SpeechReader />\n        </Box>\n\n        <Box sx={{ backgroundColor: \"white\", height: \"5vh\"}}>\n          <SpeechToText />\n        </Box>\n      </Stack>\n    </div>\n  );\n};\n\nexport default Interview;\n\n","/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/SpeechToText.jsx",[],[],"/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/Avatar.jsx",["98"],[],"import React from \"react\";\n\nfunction Avatar() {\n  return(\n    <div>\n        <center><img display=\"block\" width= \"55%\" height= \"100%\" \n        src = \"https://img.freepik.com/free-photo/business-job-interview-concept_1421-77.jpg?w=900&t=st=1698335011~exp=1698335611~hmac=6378f07665023493e93dd628968956c7f7853a76f1115b862c62dfca671d90ae\"/>\n        </center>\n    </div>\n  );\n};\n\nexport default Avatar;\n\n","/home/maryam/Documents/GitHub/graduation_project/client/src/components/Navbar.jsx",[],[],"/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/WebGazer.jsx",["99","100","101"],[],"import React, { useEffect } from \"react\";\n\nfunction WebGazer() {\n  \n  window.saveDataAcrossSessions = true\n\n  const LOOK_DELAY = 3000\n  const LEFT_CUTOFF = window.innerWidth / 4\n  const RIGHT_CUTOFF = window.innerWidth - window.innerWidth / 4\n\n  let startLookTime = Number.POSITIVE_INFINITY \n  let lookDirection = null\n\n\n  function displayWarning(message) {\n    // Create a new element to display the warning message.\n    const warningElement = document.createElement(\"div\");\n\n    // Set the text content of the new element.\n    warningElement.textContent = message;\n\n    // Add a CSS class to the new element to style it as a warning message.\n    warningElement.classList.add(\"warning\");\n\n    // Append the new element to the body of the webpage.\n    document.body.appendChild(warningElement);\n  }\n\n  const webgazer = window.webgazer\n  webgazer.setGazeListener((data, timestamp) => {\n    if(data == null) return\n\n    if (data.x < LEFT_CUTOFF && lookDirection != 'LEFT'){\n      startLookTime = timestamp\n      lookDirection = \"LEFT\"\n    } \n    else if (data.x > RIGHT_CUTOFF && lookDirection !== \"RIGHT\"){\n      startLookTime = timestamp\n      lookDirection = \"RIGHT\"\n    } \n    else if (data.x >= LEFT_CUTOFF && data.x <= RIGHT_CUTOFF){\n      startLookTime = Number.POSITIVE_INFINITY\n      lookDirection = null\n    }\n\n    if (startLookTime + LOOK_DELAY < timestamp) {\n      if (lookDirection === \"LEFT\") {\n      //   imageElement.classList.add(\"left\")\n      alert('This is an alert!');\n      } else {\n      //   imageElement.classList.add(\"right\")\n      alert('This is an alert!');\n      }\n      // console.log(\"here\")\n    }\n\n  }).begin();\n\n  return(\n    <div>\n    </div>\n  );\n\n};\n\nexport default WebGazer;\n\n","/home/maryam/Documents/GitHub/graduation_project/client/src/pages/Interview/SpeechReader.jsx",["102","103","104","105","106","107"],[],"// Create a new file named `SpeechReader.js` inside the `src` directory\r\nimport React, { useState } from 'react';\r\nimport { useSpeechSynthesis } from 'react-speech-kit';\r\nimport question from './questions.json';\r\n\r\nconst SpeechReader = () => {\r\n  const [textToSpeak, setTextToSpeak] = useState('');\r\n  const [dataset, setDataset] = useState([]);\r\n\r\n//   const handleTextChange = (event) => {\r\n//     setTextToSpeak(event.target.value);\r\n//   };\r\n\r\n  const handleSpeakClick = (data) => {\r\n    const utterance = new SpeechSynthesisUtterance();\r\n    utterance.text = data;\r\n    utterance.voice = window.speechSynthesis.getVoices()[0]; // Select the desired voice\r\n    utterance.rate = 1.0; // Adjust speech rate\r\n    speechSynthesis.speak(utterance);\r\n  };\r\n\r\n//   const fetchDataset = async () => {\r\n//     const response = await fetch('https://github.com/jdorfman/awesome-json-datasets');\r\n//     // response = await fetch('questions.json');\r\n//     const data = await response.json();\r\n//     setDataset(data);\r\n//     //.log(data);\r\n\r\n//   };\r\n\r\nasync function delay_time() {\r\n    // await delay(5000);\r\n    console.log(\"This message will be logged after 3 seconds\");\r\n  }\r\n\r\n  const handleReadFromDataset = () => {\r\n     //fetchDataset();\r\n    question.map(q => {\r\n        for(let i=0; i<3; i++){\r\n            // console.log(q.result[i].question);\r\n            setTextToSpeak(q.result[i].question);\r\n            var data = q.result[i].question;\r\n            console.log(data);\r\n            handleSpeakClick(data);\r\n            //delay_time();\r\n        }\r\n       \r\n    })\r\n    //  .catch(error => console.log('error'))\r\n    // const selectedText = dataset[Math.floor(Math.random() * dataset.length)].text;\r\n   // const selectedText = dataset;\r\n   // console.log(selectedText);\r\n   // setTextToSpeak(selectedText);\r\n    \r\n  };\r\n\r\n  return (\r\n    <div>\r\n      {/* <input type=\"text\" value={textToSpeak} onChange={handleTextChange} />\r\n      <button onClick={handleSpeakClick}>Speak</button> */}\r\n      <button onClick={handleReadFromDataset}>Read from Dataset</button>\r\n      {/* <ul>\r\n        {dataset.map((item) => (\r\n          <li key={item.id}>{item.text}</li>\r\n        ))}\r\n      </ul> */}\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default SpeechReader;",{"ruleId":"108","severity":1,"message":"109","line":1,"column":17,"nodeType":"110","messageId":"111","endLine":1,"endColumn":26},{"ruleId":"108","severity":1,"message":"112","line":16,"column":12,"nodeType":"110","messageId":"111","endLine":16,"endColumn":26},{"ruleId":"113","severity":1,"message":"114","line":34,"column":47,"nodeType":"115","messageId":"116","endLine":34,"endColumn":49},{"ruleId":"117","severity":1,"message":"118","line":62,"column":7,"nodeType":"119","endLine":62,"endColumn":206},{"ruleId":"108","severity":1,"message":"109","line":1,"column":17,"nodeType":"110","messageId":"111","endLine":1,"endColumn":26},{"ruleId":"108","severity":1,"message":"120","line":3,"column":10,"nodeType":"110","messageId":"111","endLine":3,"endColumn":28},{"ruleId":"108","severity":1,"message":"121","line":7,"column":10,"nodeType":"110","messageId":"111","endLine":7,"endColumn":21},{"ruleId":"108","severity":1,"message":"122","line":8,"column":10,"nodeType":"110","messageId":"111","endLine":8,"endColumn":17},{"ruleId":"108","severity":1,"message":"123","line":8,"column":19,"nodeType":"110","messageId":"111","endLine":8,"endColumn":29},{"ruleId":"108","severity":1,"message":"124","line":31,"column":16,"nodeType":"110","messageId":"111","endLine":31,"endColumn":26},{"ruleId":"125","severity":2,"message":"126","line":32,"column":11,"nodeType":"110","messageId":"127","endLine":32,"endColumn":16},{"ruleId":"128","severity":1,"message":"129","line":38,"column":20,"nodeType":"130","messageId":"131","endLine":38,"endColumn":22},{"ruleId":"108","severity":1,"message":"132","line":3,"column":17,"nodeType":"110","messageId":"111","endLine":3,"endColumn":25},{"ruleId":"108","severity":1,"message":"109","line":3,"column":27,"nodeType":"110","messageId":"111","endLine":3,"endColumn":36},{"ruleId":"108","severity":1,"message":"109","line":1,"column":17,"nodeType":"110","messageId":"111","endLine":1,"endColumn":26},{"ruleId":"108","severity":1,"message":"133","line":4,"column":8,"nodeType":"110","messageId":"111","endLine":4,"endColumn":16},{"ruleId":"117","severity":1,"message":"118","line":6,"column":17,"nodeType":"119","endLine":7,"endColumn":203},{"ruleId":"108","severity":1,"message":"109","line":1,"column":17,"nodeType":"110","messageId":"111","endLine":1,"endColumn":26},{"ruleId":"108","severity":1,"message":"112","line":15,"column":12,"nodeType":"110","messageId":"111","endLine":15,"endColumn":26},{"ruleId":"113","severity":1,"message":"114","line":33,"column":47,"nodeType":"115","messageId":"116","endLine":33,"endColumn":49},{"ruleId":"108","severity":1,"message":"120","line":3,"column":10,"nodeType":"110","messageId":"111","endLine":3,"endColumn":28},{"ruleId":"108","severity":1,"message":"121","line":7,"column":10,"nodeType":"110","messageId":"111","endLine":7,"endColumn":21},{"ruleId":"108","severity":1,"message":"122","line":8,"column":10,"nodeType":"110","messageId":"111","endLine":8,"endColumn":17},{"ruleId":"108","severity":1,"message":"123","line":8,"column":19,"nodeType":"110","messageId":"111","endLine":8,"endColumn":29},{"ruleId":"108","severity":1,"message":"124","line":31,"column":16,"nodeType":"110","messageId":"111","endLine":31,"endColumn":26},{"ruleId":"128","severity":1,"message":"129","line":38,"column":20,"nodeType":"130","messageId":"131","endLine":38,"endColumn":22},"no-unused-vars","'useEffect' is defined but never used.","Identifier","unusedVar","'displayWarning' is defined but never used.","eqeqeq","Expected '!==' and instead saw '!='.","BinaryExpression","unexpected","jsx-a11y/alt-text","img elements must have an alt prop, either with meaningful text, or an empty string for decorative images.","JSXOpeningElement","'useSpeechSynthesis' is defined but never used.","'textToSpeak' is assigned a value but never used.","'dataset' is assigned a value but never used.","'setDataset' is assigned a value but never used.","'delay_time' is defined but never used.","no-undef","'delay' is not defined.","undef","array-callback-return","Array.prototype.map() expects a return value from arrow function.","ArrowFunctionExpression","expectedInside","'useState' is defined but never used.","'WebGazer' is defined but never used."]